[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Chronic_Kidney_Disease",
    "section": "",
    "text": "Preface\nThis is a Quarto book."
  },
  {
    "objectID": "index.html#software-conventions",
    "href": "index.html#software-conventions",
    "title": "Chronic_Kidney_Disease",
    "section": "Software conventions",
    "text": "Software conventions\n\n1 + 1\n\n2\n\n\nTo learn more about Quarto books visit https://quarto.org/docs/books."
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "Chronic_Kidney_Disease",
    "section": "Acknowledgments",
    "text": "Acknowledgments\nBlah, blah, blah…"
  },
  {
    "objectID": "Chronic_Kidney_Disease.html#busines-understanding",
    "href": "Chronic_Kidney_Disease.html#busines-understanding",
    "title": "1  ——————————– TUGAS PROYEK SAINS DATA ——————————-",
    "section": "1.1 1. Busines Understanding",
    "text": "1.1 1. Busines Understanding\n\n\n1.1.1 Tujuan Proyek\nMelakukan Klasifikasi penyakit ginjal kronis untuk memprediksi apakah seseorang terkena penyakit ginjal kronis atau tidak. Untuk menentukan prediksi penyakit ginjal kronis dapat dilihat pada kelas berikut:\n\nApabila data memiliki kelas ckd (Chronic Kidney Disease) maka dinyatakan terkena penyakit ginjal kronis\nApabila data memiliki kelas notckd (Not Chronic Kidney Disease) maka dinyatakan tidak terkena penyakit ginjal kronis\n\nUntuk menentukan klasifikasi penyakit ginjal kronis dapat dilihat dari ciri-ciri sebagai berikut:\n\n\n1.1.2 DESKRIPSI FITUR\n\nAge (umur)\nBlood Pressure (Tekanan Darah)\n\nbp in mm/Hg\n\nSpecific Gravity (Berat jenis Urin)\n\nsg - (1.005,1.010,1.015,1.020,1.025)\n\nAlbumin (Kadar albumin dalam urin)\n\nal - (0,1,2,3,4,5)\n\nSugar (Kadar gula dalam urin)\n\nsu - (0,1,2,3,4,5)\n\nRed Blood Cells (sel darah merah)\n\nrbc - (normal,abnormal)\n\nPus Cell (sel darah putih)\n\npc - (normal,abnormal)\n\nPus Cell clumps (gumpalan sel darah putih)\n\npcc - (present,notpresent)\n\nBacteria (bakteri dalam urin)\n\nba - (present,notpresent)\n\nBlood Glucose Random (kadar glukosa darah)\n\nbgr in mgs/dl\n\nBlood Urea (kadar urea dalam darah)\n\nbu in mgs/dl\n\nSerum Creatinine (kadar kreatin dalam darah)\n\nsc in mgs/dl\n\nSodium (kadar natrium dalam darah)\n\nsod in mEq/L\n\nPotassium (kadar kalium dalam darah)\n\npot in mEq/L\n\nHemoglobin (kadar hemoglobin)\n\nhemo in gms\n\nPacked Cell Volume (volume sel darah merah dalam darah)\nWhite Blood Cell Count (jumlah sel darah putih)\n\nwc in cells/cumm\n\nRed Blood Cell Count (jumlah sel darah merah)\n\nrc in millions/cmm\n\nHypertension (hipertensi)\n\nhtn - (yes,no)\n\nDiabetes Mellitus(keberadaan diabetes melitus)\n\ndm - (yes,no)\n\nCoronary Artery Disease (keberadaan penyakit arteri koroner)\n\ncad - (yes,no)\n\nAppetite (kondisi nafsu makan)\n\nappet - (good,poor)\n\nPedal Edema (keberadaan edema pada kaki)\n\npe - (yes,no)\n\nAnemia (keberadaan anemia)\n\nane - (yes,no)\n\n\nUntuk refrensi bisa diakses link berikut : https://archive.ics.uci.edu/dataset/336/chronic+kidney+disease"
  },
  {
    "objectID": "Chronic_Kidney_Disease.html#data-understanding",
    "href": "Chronic_Kidney_Disease.html#data-understanding",
    "title": "1  ——————————– TUGAS PROYEK SAINS DATA ——————————-",
    "section": "1.2 2. Data Understanding",
    "text": "1.2 2. Data Understanding\nTujuan dari data understanding ini adalah untuk memahami struktur, karakteristik, dan kualitas data yang akan digunakan untuk analisis lebih lanjut.\nAdapun hal - hal yang perlu dilakukan data understanding sebagai berikut : 1. Pengumpulan Data 2. Eksplorasi Data - Mengidentifikasi jumlah data - Mendeskripsikan setiap fitur pada data * tipe data * deskripsi data - Visualisasi data 3. Mengidentifikasi missing values setiap fitur atau kolom 4. Mengidentifikasi outlier\n\n\n1.2.1 Pengumpulan Data\nData ini diambil selama periode 2 bulan di India dengan 25 fitur (misalnya jumlah sel darah merah, jumlah sel darah putih, dll). Targetnya adalah ‘klasifikasi’, yaitu ‘ckd’ atau ‘notckd’ - ckd = penyakit ginjal kronis. Penyakit Ginjal Kronis adalah suatu kondisi di mana fungsi ginjal secara bertahap menurun selama periode waktu yang cukup lama. Ginjal memiliki peran penting dalam menyaring limbah dan kelebihan cairan dari darah, serta dalam menjaga keseimbangan elektrolit dan tekanan darah.\n\n\n1.2.2 Eksplorasi Data\nEksplorasi data awal adalah tahap awal dalam proses analisis data yang bertujuan untuk memahami sifat dan karakteristik data sebelum dilakukan analisis lebih lanjut. Langkah-langkah eksplorasi data awal memberikan wawasan awal tentang isi dataset dan membantu peneliti atau analis data dalam merencanakan pendekatan analisis yang tepat.\nMengidentifikasi jumlah data\nMengidentifikasi jumlah data merupakan langkah awal untuk memahami skala dataset yang akan kita lakukan pengolahan. Dengan mengetahui jumlah baris (observasi) dan kolom (fitur) atau gambaran umum tentang ukuran data.\nJumlah Dataset sebanyak 400 dengan rincian sebagai berikut :\n\nChronic Kidney Disease (ckd) = 250\nNot Chronic Kidney Disesae (notckd) = 150\n\n\n#Menyambungkan Google Drive dengan Google Colab\nfrom google.colab import drive\ndrive.mount(\"/content/drive\")\n%cd /content/drive/MyDrive/PSD/\n\nMounted at /content/drive\n/content/drive/MyDrive/PSD\n\n\n\nimport pandas as pd\ndf = pd.read_csv('kidney_disease.csv')\ndf.head(5)\n\n\n  \n    \n\n\n\n\n\n\nid\nage\nbp\nsg\nal\nsu\nrbc\npc\npcc\nba\n...\npcv\nwc\nrc\nhtn\ndm\ncad\nappet\npe\nane\nclassification\n\n\n\n\n0\n0\n48.0\n80.0\n1.020\n1.0\n0.0\nNaN\nnormal\nnotpresent\nnotpresent\n...\n44\n7800\n5.2\nyes\nyes\nno\ngood\nno\nno\nckd\n\n\n1\n1\n7.0\n50.0\n1.020\n4.0\n0.0\nNaN\nnormal\nnotpresent\nnotpresent\n...\n38\n6000\nNaN\nno\nno\nno\ngood\nno\nno\nckd\n\n\n2\n2\n62.0\n80.0\n1.010\n2.0\n3.0\nnormal\nnormal\nnotpresent\nnotpresent\n...\n31\n7500\nNaN\nno\nyes\nno\npoor\nno\nyes\nckd\n\n\n3\n3\n48.0\n70.0\n1.005\n4.0\n0.0\nnormal\nabnormal\npresent\nnotpresent\n...\n32\n6700\n3.9\nyes\nno\nno\npoor\nyes\nyes\nckd\n\n\n4\n4\n51.0\n80.0\n1.010\n2.0\n0.0\nnormal\nnormal\nnotpresent\nnotpresent\n...\n35\n7300\n4.6\nno\nno\nno\ngood\nno\nno\nckd\n\n\n\n\n\n5 rows × 26 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n# Rincian dataset (banyak data dan kolom)\n\nprint(\"Banyaknya data : \", df.shape[0])\nprint(\"Banyaknya kolom : \", df.shape[1])\n\nBanyaknya data :  400\nBanyaknya kolom :  26\n\n\nIdenItifikasi Proporsi Jumlah Masing-masing Kelas Dalam Data\nUntuk mencapai hasil maksimal, perlu dilakukan identifikasi proporsi jumlah data dari masing-masing kelas. Dengan begitu ketidakseimbangan data disetiap kelas pada data penyakit ginjal kronis ini dapat ditangani dengan menyeimbangkan jumlah data disetiap kelasnya.\n\n# Menghitung jumlah target pada data tanpa outlier\ntarget = df['classification'].value_counts()\n\nprint(\"Jumlah data pada tiap target :\")\nprint(target)\n\nJumlah data pada tiap target :\nckd       248\nnotckd    150\nckd\\t       2\nName: classification, dtype: int64\n\n\nDiperoleh identifikasi setiap target sebanyak 2 kelas yaitu ckd dan notckd. Kelas ckd memiliki jumlah yang lebih besar dibandingkan dengan notckd. Akan tetapi selisih dari jumlah data tersebut tidak terlalu jauh, sehingga tidak perlu dilakukan balancing data.\nMendeskripsikan setiap fitur\nChronic Kidney Disease / Penyakit Ginjal Kronis pada dataset ini terdapat 25 fitur dengan jumlah data sebanyak 400.\n\ndf.columns\n\nIndex(['id', 'age', 'bp', 'sg', 'al', 'su', 'rbc', 'pc', 'pcc', 'ba', 'bgr',\n       'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv', 'wc', 'rc', 'htn', 'dm', 'cad',\n       'appet', 'pe', 'ane', 'classification'],\n      dtype='object')\n\n\n\n\n1.2.3 Tipe Data\nBerikut Macam - Macam Data yang ada pada data ini.\n\nTipe nominal Tipe nominal adalah variabel yang menggambarkan kategori tanpa memiliki urutan tertentu atau tingkat peringkat yang melekat. Berikut tipe nominal yang terdapat pada data ini :\n\nmemiliki value 1.005,1.010,1.015,1.020, dan 1.025. &gt; yaitu fitur : ‘Specific Gravity (sg)’\nmemiliki value 0,1,2,3,4, dan 5. &gt; yaitu pada fitur ‘Albumin (al)’ dan Sugar (su)\nmemiliki value normal dan abnormal. &gt; yakni pada fitur ‘Red Blood Cells(rbc)’dan’Pus Cell(pc)’\nmemiliki value normal dan abnormal. &gt; yakni pada fitur ‘Red Blood Cells(rbc)’dan’Pus Cell(pc)’\nmemiliki value present dan notpresent. &gt; yakni pada fitur ‘Pus Cell clumps(pcc)’ dan ‘Bacteria(ba)’\nmemiliki value yes dan no. &gt; yakni pada fitur ‘Hypertension(htn)’, ‘Diabetes Mellitus(dm)’, ‘Coronary Artery Disease(cad)’, ‘Pedal Edema(pe)’, dan ‘Anemia’(ane)\nmemiliki value ckd dan notckd. &gt; yakni pada fitur ‘Classification’\nmemiliki tipe data numeric. &gt; yakni pada fitur ‘Age’, ‘Blood Pressure’, ‘Blood Glucose Random’, ‘Blood Urea’, ‘Serum Creatinine’, ‘Sodium’, ‘Potassium’, ‘Hemoglobin’, ‘Packed Cell Volume’, ‘White Blood Cell Count’, dan ‘Red Blood Cell Count’,\n\nTipe ordinal Tipe ordinal adalah variabel yang memiliki kategori dengan urutan atau tingkat peringkat yang dapat dibandingkan. Berikut tipe ordinal yang terdapat pada data ini : &gt; yakni pada fitur ‘Appetite’ dengan value good dan poor\n\n\n\n1.2.4 Deskripsi Data\n\nAge (umur)\n\numur dalam tahun Data diperoleh dari usia seseorang saat pengambilan data\n\nBlood Pressure (Tekanan Darah)\n\nbp in mm/Hg\n\n\nPeningkatan tekanan darah menjadi indikator atau faktor resiko dari penyakit ginjal kronis. Tekanan darah dapat diukur dengan menggunakan alat pengukur pengukur tekanan darah yaitu sphygmomanometer. Pengukurannya ada 2 cara yaiut :tekanan sistolik (saat jantung berkontraksi) dan tekanan diastolik (saat jantung beristirahat). Keduanya diukur dalam milimeter air raksa (mmHg).\n\nSpecific Gravity (Berat jenis Urin)\n\nsg - (1.005,1.010,1.015,1.020,1.025)\n\n\nBerat jenis urin mengukur seberapa padat atau encer urin seseorang. Normalnya, urin yang diproduksi oleh ginjal memiliki berat jenis tertentu yang mencerminkan kemampuan ginjal untuk menyaring zat-zat dalam darah dan membuangnya melalui urin. Pada orang dengan PGK, ginjal mungkin mengalami kesulitan menyaring dan membuang zat-zat tertentu, sehingga dapat terjadi perubahan pada berat jenis urin. Pengambilan data berat jenis urin dapat dilakukan dengan tiga cara yaitu Urinometer, Strip Uji Urin, dan Laboratorium. Untuk berat jenis urin normal berkisar antara 1.010 hingga 1.025. Akan tetapi, terdapat beberapa faktor yang mempengaruhi berat jenis urine normal, salah satunya pada kondisi medis seperti gagal ginjal, infeksi saluran kemih, dan diabetes dapat memiliki berat jenis urine dengan rentang 1.020 hingga 1.030 g/ml.\n\n\nReferensi : https://jenis.id/berat-jenis-urine-normal/\n\nAlbumin (Kadar albumin dalam urin)\n\nal - (0,1,2,3,4,5)\n\n\nAlbumin adalah salah satu protein dalam darah yang berperan penting dalam mempertahankan tekanan osmotik darah, serta membantu dalam transportasi zat-zat seperti hormon dan nutrisi. Albumin juga dapat diukur dalam urin, dan tingkat albumin dalam urin sering digunakan sebagai indikator dalam klasifikasi penyakit ginjal kronis (PGK). Pengambilan data albumin dapat dilakukan dengan dua cara yaitu Uji Tinja (Dipstick Test) dan Uji Laboratorium. Untuk penjelasan rentang albumin 0,1,2,3,4,5 sebagai berikut:\n\n\n\n0: Tidak ada atau kadar albumin sangat rendah, yang mungkin dianggap normal\n\n\n1: Tingkat mikroalbuminuria yang rendah, mungkin menunjukkan adanya kerusakan ginjal yang awal.\n\n\n2: Peningkatan tingkat mikroalbuminuria, menunjukkan adanya kerusakan ginjal yang sedang.\n\n\n3-4: Mungkin menunjukkan peningkatan yang lebih signifikan dalam tingkat albuminuria, mencerminkan kerusakan ginjal yang lebih parah.\n\n\n5: Paling mungkin menunjukkan tingkat albuminuria yang sangat tinggi, mungkin dianggap sebagai makroalbuminuria, yang sering kali dihubungkan dengan progresi penyakit ginjal yang signifikan.\n\n\nSugar (Kadar gula dalam urin)\n\nsu - (0,1,2,3,4,5)\n\n\nKadar glukosa dalam darah dapat memberikan indikasi tentang fungsi ginjal dan kesehatan tubuh secara keseluruhan. Penyakit ginjal kronis bisa memengaruhi metabolisme glukosa dan menyebabkan peningkatan kadar gula dalam darah, yang dapat terlihat dalam urin. Pengambilan data albumin dapat dilakukan dengan cara Uji Pendektesian Gula. Untuk alat yang digunakan yaitu mikroskop atau alat tes kimia. Untuk penjelasan rentang albumin 0,1,2,3,4,5 sebagai berikut:\n\n\n0: Kadar gula dalam urin yang diukur sebagai 0 mungkin menunjukkan bahwa tidak ada atau hanya sedikit glukosa yang terdeteksi dalam urin. Dalam keadaan normal, urin seharusnya tidak mengandung glukosa yang signifikan.\n\n\n1: Kadar gula dalam urin sebesar 1 mungkin menunjukkan adanya sedikit glukosa dalam urin. Meskipun nilai ini masih di bawah ambang batas normal, bisa menjadi perhatian dan memerlukan pemantauan lebih lanjut.\n\n\n2: Kadar gula dalam urin sebesar 2 mungkin menunjukkan peningkatan glukosa yang lebih signifikan dalam urin. Ini bisa mengindikasikan adanya gangguan metabolisme glukosa atau ketidaknormalan pada ginjal.\n\n\n3-4: Kadar gula dalam urin sebesar 3 atau 4 mungkin menunjukkan peningkatan yang lebih signifikan dalam glukosa urin. Ini bisa terkait dengan masalah metabolik yang lebih serius dan perlu ditinjau lebih lanjut oleh profesional medis.\n\n\n5: Kadar gula dalam urin sebesar 5 mungkin menunjukkan tingkat glukosa yang sangat tinggi dalam urin. Ini bisa merupakan tanda gangguan metabolisme glukosa yang serius atau masalah ginjal yang signifikan.\n\nRed Blood Cells (sel darah merah)\n\nrbc - (normal,abnormal)\n\n\nSel darah merah (eritrosit) adalah komponen seluler darah yang membawa oksigen dari paru-paru ke seluruh tubuh dan mengangkut karbon dioksida dari seluruh tubuh kembali ke paru-paru untuk dikeluarkan. Kaitannya dengan penyakit ginjal kronis adalah penyakit ini dapat menyebabkan anemia (kurang darah) karena produksi hormon eritropoietin berkurang, ini diperlukan untuk merangsang pembentukan sel darah merah di dalam sumsum tulang. Pengambilan data sel darah merah dapat dilakukan dengan 3 cara yaitu, Hitung Sel Darah Merah(RBC Count), Hemoglobin (Hb) dan Hematokrit (Hct), dan Indeks Sel Darah Merah (MCV, MCH, MCHC). Untuk penjelasan sel darah merah dikatakan normal dan abnormal sebagai berikut :\n\n\nnormal : Jumlah sel darah merah, kadar hemoglobin, dan parameter terkait dalam rentang normal menunjukkan fungsi normal sel darah merah. Tidak adanya anemia atau gangguan produksi sel darah merah.\n\n\nabnormal : Pengurangan jumlah sel darah merah, kadar hemoglobin, atau perubahan pada indeks sel darah merah bisa menjadi indikasi adanya anemia yang dapat terkait dengan PGK.\n\nPus Cell (sel darah putih)\n\npc - (normal,abnormal)\n\n\nSel darah putih (leukosit) adalah sel-sel yang berperan dalam sistem kekebalan tubuh. Penyakit ginjal kronis (PGK) dapat mempengaruhi sistem kekebalan tubuh, dan perubahan pada jumlah sel darah putih dapat menjadi fitur yang diobservasi dalam klasifikasi PGK. Peningkatan jumlah sel darah putih dapat mencerminkan respon kekebalan tubuh terhadap peradangan atau infeksi yang terkait dengan PGK. Pengambilan data sel darah putih dapat dilakukan dengan 2 cara yaitu Tes Darah Rutin (Complete Blood Count/CBC) dan Darah Urin. Untuk penjelasan sel darah putih dikatakan normal dan abnormal sebagai berikut :\n\n\nnormal : Jumlah sel darah putih dalam darah biasanya berada dalam rentang normal yaitu berkisar antara 4,500−10.000 sel/mm³.\n\n\nabnormal : Terjadinya kekurangan atau kelebihan sel darah putih, untuk kekurangan sel darah merah yaitu sekitar 4.000 sel/mm³. Dan untuk kelebihan sel darah putih yaitu lebih dari angka 11.000 sel/mm³.\n\nPus Cell clumps (gumpalan sel darah putih)\n\npcc - (present,notpresent)\n\n\nPus Cell Clumps (klompok sel darah putih) dalam urin dapat menunjukkan adanya peradangan atau infeksi dalam sistem kemih, termasuk pada ginjal, yang dapat terkait dengan penyakit ginjal kronis (PGK). Pengambilan data sel darah putih dapat dilakukan dengan 2 cara yaitu Uji Urin Mikroskopis dan Strip Uji Urin. Untuk penjelasan Pus Cell clumps dikatakan present dan not present sebagai berikut :\n\n\npresent : adanya peradangan atau infeksi dalam sistem kemih pada saat pemeriksaan urin.\n\n\nnot present : tidak adanya peradangan atau infeksi dalam sistem kemih pada saat pemeriksaan urin.\n\nBacteria (bakteri dalam urin)\n\nba - (present,notpresent)\n\n\nBakteri dalam urin dapat menunjukkan adanya infeksi saluran kemih, yang bisa terkait dengan kondisi ginjal atau sistem kemih yang mendasari. Pengambilan data sel darah putih dapat dilakukan dengan cara uji laboratorium pada sampel urin menggunakan alat mikroskop atau alat tes kimia. Untuk penjelasan bacteria dikatakan present dan not present sebagai berikut :\n\n\npresent : adanya keberadaan bakteri dalam sistem kemih pada saat pemeriksaan urin.\n\n\nnot present : tidak adanya keberadaan bakteri dalam sistem kemih pada saat pemeriksaan urin.\n\nBlood Glucose Random (kadar glukosa darah)\n\nbgr in mgs/dl\n\n\nGlukosuria adalah kondisi terdapatnya ekskresi glukosa di dalam urine yang mengacu pada kondisi patologis seperti diabetes mellitus atau gangguan fungsi ginjal. Adanya ekskresi glukosa di dalam urine dapat terjadi pada keadaan dengan kadar glukosa plasma yang normal maupun kadar glukosa plasma yang tinggi. Diagnosis glukosuria dapat ditegakkan melalui pemeriksaan urinalisis. Bila pada pemeriksaan ditemukan kadar glukosa di atas 25 mg/dl pada urine segar acak (random fresh urine), maka pasien dapat dikatakan mengalami glukosuria.\n\nBlood Urea (kadar urea dalam darah)\n\nbu in mgs/dl\n\n\nKadar ureum tinggi bisa menandakan bahwa ginjal Anda tidak berfungsi dengan baik. Idealnya, ginjal berfungsi menyaring dan membuang ureum dari darah melalui urine. Jika menumpuk di darah, ureum dapat menimbulkan beragam keluhan dan gangguan kesehatan. Ureum merupakan zat sisa dari pemecahan protein dan asam amino di dalam hati. Kadar ureum dapat diukur melalui tes blood urea nitrogen (BUN). Zat ini bersifat racun dan perlu segera dikeluarkan dari tubuh melalui ginjal. Batas normal kadar ureum berdasarkan usia dan jenis kelamin sebagai berikut :\n\n\nPria dewasa: 8–24 mg/dL\nWanita dewasa: 6–21 mg/dL\nAnak usia 1–17 tahun: 7–20 mg/dL\n\nSerum Creatinine (kadar kreatin dalam darah)\n\nsc in mgs/dl\n\n\nKreatinin adalah zat limbah dalam darah yang diproduksi oleh jaringan otot saat Anda bergerak atau beraktivitas. Jumlah kreatinin di dalam darah diatur oleh ginjal. Itulah alasan mengapa pemeriksaan kadar kreatinin sering dilakukan sebagai salah satu cara untuk menilai fungsi ginjal.Normalnya, kreatinin dalam darah akan disaring oleh ginjal, lalu dibuang keluar melalui urine. Ketika ginjal bermasalah atau fungsinya terganggu, kreatinin tidak dapat disaring dengan baik. Hal ini dapat menyebabkan kadar kreatinin dalam darah meningkat dan dan menyebabkan fungsi ginjal terganggu.Kadar kreatinin normal dalam darah pada orang dewasa adalah 0,8–1,2 mg/dL. Namun, rentang nilai tersebut mungkin saja bervariasi pada setiap laboratorium.\n\nSodium (kadar natrium dalam darah)\n\nsod in mEq/L\n\n\nSodium adalah elektrolit yang sangat penting dalam tubuh dan memiliki peran dalam menjaga keseimbangan cairan, tekanan darah, dan fungsi saraf dan otot. Dalam konteks penyakit ginjal kronis (PGK), kadar sodium dalam tubuh dapat berubah akibat gangguan fungsi ginjal dan keseimbangan elektrolit yang terkait. Pengambilan data sel darah putih dapat dilakukan dengan 3 cara yaitu, Tes Elektrolit, Tes Fungsi Ginjal, dan Pemeriksaan Urine. Standar kebutuhan sodium seseorang dewasa berklisar antara 1500-2300 mg sodium.\n\nPotassium (kadar kalium dalam darah)\n\npot in mEq/L\n\n\nKalium atau potasium adalah mineral yang membantu tubuh menyeimbangkan cairan dan mendukung fungsi sel, saraf, dan otot. Senyawa ini ditemukan dalam berbagai tingkat di banyak makanan, terutama buah-buahan dan sayuran. Penting untuk memiliki keseimbangan kalium yang tepat dalam darah, dan kadar umumnya harus tetap antara 3,5 dan 5,0 milliequivalent per liter (mEq/L).\n\nHemoglobin (kadar hemoglobin)\n\nhemo in gms\n\n\nHemoglobin adalah protein dalam sel darah merah yang berperan penting dalam mengangkut oksigen dari paru-paru ke seluruh tubuh dan membawa karbon dioksida kembali ke paru-paru untuk dikeluarkan. Pengambilan data sel darah putih dapat dilakukan dengan 2 cara yaitu Tes Darah Rutin(Complete Blood Count/CBC) dan Uji Hematokrit. Kadar hemoglobin normal pada wanita dewasa berkisar antara 12–15 g/dL, sedangkan kadar hemoglobin pada pria dewasa berkisar antara 13–17 g/dL.\n\nPacked Cell Volume (volume sel darah merah dalam darah)\n\nPacked Cell Volume (PCV), juga dikenal sebagai Hematocrit, adalah ukuran persentase volume darah yang terdiri dari sel-sel darah merah. Meskipun PCV umumnya bukan fitur utama dalam klasifikasi penyakit ginjal kronis (PGK), perubahan dalam PCV dapat memberikan indikasi tentang kondisi kesehatan secara keseluruhan, termasuk kemungkinan dampak PGK terhadap produksi sel darah merah. Pengambilan data sel darah putih dapat dilakukan dengan 3 cara yaitu, Pengambilan Sampel Darah, Sentrifugasi, dan Pengukuran PCV. Rentang nilai normal PCV dapat bervariasi tergantung pada usia, jenis kelamin, dan faktor lainnya. Sebagai contoh, nilai normal PCV pada orang dewasa pria biasanya berkisar antara 38% hingga 52%, sementara pada wanita berkisar antara 33% hingga 47%.\n\nWhite Blood Cell Count (jumlah sel darah putih)\n\nwc in cells/cumm\n\n\nJumlah sel darah putih (leukosit) dalam darah memberikan informasi tentang respons sistem kekebalan tubuh terhadap infeksi atau peradangan yang dapat terkait dengan PGK. Pengambilan data sel darah putih dapat dilakukan dengan cara Tes Darah Rutin (Complete Blood Count/CBC). Jumlah sel darah putih yang normal adalah sekitar 5.000 – 10.000/cumm.\n\nRed Blood Cell Count (jumlah sel darah merah)\n\nrc in millions/cmm\n\n\nRed Blood Cell Count (RBC count) adalah pengukuran jumlah sel darah merah dalam satu volume tertentu dari darah. Pengukuran RBC count dapat memberikan informasi penting tentang kondisi kesehatan, termasuk kemungkinan adanya masalah ginjal. Dalam konteks penyakit ginjal kronis (PGK), perubahan pada RBC count dapat mencerminkan gangguan fungsi ginjal atau kondisi medis terkait. Pengambilan data sel darah merah dapat dilakukan dengan cara Tes Darah Rutin (Complete Blood Count/CBC). Jumlah sel darah merah normal berdasarkan rentang umur dan jenis kelamin sebagai berikut :\n\n\nPria: 4,7 – 6,1 juta per mikroliter darah\nWanita: 4,2 – 5,4 juta per mikroliter darah\nAnak-anak: 4 – 5,5 juta per mikroliter darah\n\nHypertension (hipertensi)\n\nhtn - (yes,no)\n\n\nHipertensi atau tekanan darah tinggi adalah salah satu faktor risiko utama untuk perkembangan penyakit ginjal kronis (PGK). Kondisi ini dapat merusak pembuluh darah di ginjal dan menyebabkan kerusakan ginjal secara bertahap. Oleh karena itu, hipertensi sering diidentifikasi sebagai fitur atau faktor dalam klasifikasi penyakit ginjal kronis. Pengambilan data hipertensi dapat dilakukan dengan 3 cara yaitu, Pengukuran Tekanan Darah, Minoritas Tekanan Darah Berkala, dan Rekam Medis. Untuk penjelasan hipertensi dikatakan yes dan no sebagai berikut :\n\n\nyes : Jika tekanan darah pasien consistently (secara konsisten) berada di atas ambang batas normal (umumnya diukur sebagai 130/80 mmHg atau lebih tinggi), ini dapat dianggap sebagai indikasi hipertensi.\nno : Jika tekanan darah pasien consistently (secara konsisten) berada di dibawah ambang batas normal (kurang dari 130/80 mmHg), ini dapat dianggap sebagai tidak terindikasi hipertensi.\n\nDiabetes Mellitus(keberadaan diabetes melitus)\n\ndm - (yes,no)\n\n\nDiabetes adalah penyakit kronis yang ditandai dengan tingginya kadar gula darah. Glukosa merupakan sumber energi utama bagi sel tubuh manusia. Akan tetapi, pada penderita diabetes, glukosa tersebut tidak dapat digunakan oleh tubuh. Pengambilan data hipertensi dapat dilakukan dengan 2 cara yaitu, Tes Glukosa Darah dan Riwayat Kesehatan. Untuk penjelasan Diabetes Melitus dikatakan yes dan no sebagai berikut :\n\n\nyes : jika seseorang memiliki riwayat Diabetes Mellitus, hasil tes glukosa darah atau HbA1c yang positif, atau sedang menjalani pengobatan untuk diabetes mellitus, maka dapat dikategorikan sebagai “Yes” untuk diabetes mellitus.\nno : Jika seseorang tidak memiliki riwayat diabetes mellitus, hasil tes glukosa darah dalam kisaran normal, dan tidak sedang menjalani pengobatan untuk diabetes mellitus, maka dapat dikategorikan sebagai “No” untuk diabetes mellitus.\n\nCoronary Artery Disease (keberadaan penyakit arteri koroner)\n\ncad - (yes,no)\n\n\nCoronary Artery Disease (CAD) atau penyakit arteri koroner adalah suatu kondisi dimana pembuluh darah koroner yang memasok darah ke jantung mengalami penyempitan atau pemblokiran. Meskipun secara langsung tidak termasuk dalam klasifikasi penyakit ginjal kronis (PGK), tetapi PGK dan CAD seringkali saling terkait dan memiliki faktor risiko bersama seperti diabetes, hipertensi, dan gangguan metabolisme lipid. Pengambilan data Coronary Artery Disease dapat dilakukan dengan melalui Riwayat Medis. Untuk penjelasan Coronary Artery Disease dikatakan yes dan no sebagai berikut :\n\n\nyes : Jika data menunjukkan adanya CAD, ini berarti bahwa pasien memiliki kondisi penyakit arteri koroner yang perlu dievaluasi dan dielola secara khusus.\nno : Jika data menunjukkan tidak adanya CAD, ini berarti bahwa pasien tidak memiliki penyakit arteri koroner berdasarkan informasi yang diperoleh.\n\nAppetite (kondisi nafsu makan)\n\nappet - (good,poor)\n\n\nNafsu makan (appetite) dapat dipengaruhi oleh penyakit ginjal kronis (PGK) dan memiliki dampak yang signifikan pada kesehatan pasien, salah satunya dampaknya yaitu penurunan nafsu makan. Pengambilan data Appetite dapat dilakukan dengan 3 cara yaitu Pengamatan klinis, Wawancara Pasien, dan Penggunaan Kuesioner. Untuk penjelasan appetite dikatakan good dan poor sebagai berikut :\n\n\ngood : Pasien dengan nafsu makan yang baik, pola makan yang memadai, dan pertahankan berat badan yang normal mungkin memiliki status nutrisi yang baik. Ini dapat menunjukkan bahwa PGK mereka mungkin masih dalam tahap awal atau lebih terkontrol.\npoor : Pasien dengan penurunan nafsu makan, kehilangan berat badan yang signifikan, atau masalah nutrisi lainnya mungkin mengalami dampak lebih serius dari PGK. Kondisi ini dapat disebabkan oleh beberapa faktor, termasuk komplikasi PGK, efek samping dari pengobatan, atau penyakit lain yang terkait.\n\nPedal Edema (keberadaan edema pada kaki)\n\npe - (yes,no)\n\n\nPedal edema merupakan suatu kondisi di mana terjadi penumpukan cairan di daerah pergelangan kaki atau bagian bawah tungkai. Edema seringkali menjadi gejala yang terkait dengan penyakit ginjal kronis (PGK) karena ginjal yang tidak berfungsi dengan baik mungkin gagal menyaring dan mengeluarkan cairan yang cukup dari tubuh. Pengambilan data Pedal edema dapat dilakukan dengan cara Pemeriksaan fisik. Untuk penjelasan Pedal Edma dikatakan yes dan no sebagai berikut :\n\n\nyes : Pedal edema terlihat atau terkonfirmasi melalui pemeriksaan fisik atau catatan pasien. Pembengkakan yang terlihat di daerah pergelangan kaki atau kaki dapat dianggap sebagai tanda pedal edema yang positif.\nno :Tidak ada tanda atau gejala edema yang terdeteksi pada pemeriksaan fisik atau melalui informasi yang diberikan oleh pasien. Pembengkakan tidak terjadi atau tidak dapat diidentifikasi.\n\nAnemia (keberadaan anemia)\n\nane - (yes,no)\n\n\nAnemia, atau kekurangan sel darah merah atau hemoglobin dalam darah, dapat terjadi pada penyakit ginjal kronis (PGK). Ginjal memiliki peran penting dalam pembentukan eritropoietin, hormon yang merangsang produksi sel darah merah dalam sumsum tulang. Gangguan pada ginjal dapat menyebabkan penurunan produksi eritropoietin dan berkontribusi pada perkembangan anemia pada pasien dengan PGK. Pengambilan data Anemia dapat dilakukan dengan cara 2 cara yaitu Tes Hemoglobin dan Hitung Jumlah Sel Darah Merah (RBC). Untuk penjelasan Anemia dikatakan yes dan no sebagai berikut :\n\n\nyes : jika hasil tes menunjukkan kadar hemoglobin yang rendah, hitung sel darah merah yang rendah, atau kadar zat besi yang rendah, ini dapat mengindikasikan adanya anemia yang terkait dengan penyakit ginjal kronis.\nno : Jika hasil tes menunjukkan kadar hemoglobin, hitung sel darah merah, dan kadar zat besi dalam kisaran normal, maka pasien mungkin tidak mengalami anemia yang terkait dengan PGK.\n\nClass (klasifikasi penyakit ginjal kronis)\n\nclass - (ckd,notckd)\n\n\nData bisa diperoleh dari diagnosis medis atau hasil tes medis yang relevan.\n\n\nVisualisasi Data\n\nimport matplotlib.pyplot as plt\n\n# df adalah DataFrame Anda\n# Ganti dengan data sesuai kebutuhan Anda\n\n# Menentukan jumlah kolom yang ingin ditampilkan\nnum_cols = min(26, len(df.columns))  # Maksimal menampilkan 25 kolom\n\n# Menentukan jumlah baris dan kolom untuk tata letak subplot\nnum_rows = (num_cols // 3) + int(num_cols % 3 != 0)\n\n# Menentukan ukuran gambar\nfig, axes = plt.subplots(num_rows, 3, figsize=(15, num_rows * 3))\n\n# Melakukan loop untuk membuat histogram untuk setiap kolom\nfor i in range(num_rows):\n    for j in range(3):\n        col_index = i * 3 + j\n        if col_index &lt; num_cols:\n            df[df.columns[col_index]].hist(ax=axes[i, j], bins=20)\n            axes[i, j].set_title(df.columns[col_index])\n\n# Menyesuaikan tata letak\nplt.tight_layout()\nplt.show()\n\nUserWarning: Glyph 9 (  ) missing from current font.\n  plt.tight_layout()\n/usr/local/lib/python3.10/dist-packages/IPython/core/pylabtools.py:151: UserWarning: Glyph 9 (  ) missing from current font.\n  fig.canvas.print_figure(bytes_io, **kw)\n\n\n\n\n\n\n\n1.2.5 Mengidentifikasi missing value\nMissing value, atau nilai yang hilang, merujuk pada keadaan di mana suatu variabel dalam data tidak memiliki nilai atau informasi yang tersedia. Keberadaan missing value dapat disebabkan oleh berbagai faktor, seperti kesalahan pengukuran, kelalaian dalam pengumpulan data, atau sengaja diabaikan. Dalam analisis data, penanganan yang tepat terhadap missing value penting karena dapat memengaruhi keakuratan dan interpretasi hasil analisis. Metode penanganan missing value melibatkan strategi seperti penghapusan data yang hilang, imputasi nilai (pengisian nilai yang hilang), atau teknik lain yang sesuai dengan karakteristik data dan tujuan analisis.\n\n# Menghitung apakah ada nilai yang hilang dalam setiap kolom\nmissing_values = df.isna().any()\n\n# Menampilkan hasil\nprint(\"Apakah ada nilai yang hilang dalam setiap kolom:\")\nprint(missing_values)\n\nApakah ada nilai yang hilang dalam setiap kolom:\nid                False\nage                True\nbp                 True\nsg                 True\nal                 True\nsu                 True\nrbc                True\npc                 True\npcc                True\nba                 True\nbgr                True\nbu                 True\nsc                 True\nsod                True\npot                True\nhemo               True\npcv                True\nwc                 True\nrc                 True\nhtn                True\ndm                 True\ncad                True\nappet              True\npe                 True\nane                True\nclassification    False\ndtype: bool\n\n\nNoted : Terdapat missing value pada data\nJumlah missing value pada tiap data\n\nmissing_values = df.isnull().sum()\nprint(\"Jumlah Missing Values dalam Setiap Kolom:\")\nprint(missing_values)\n\nJumlah Missing Values dalam Setiap Kolom:\nid                  0\nage                 9\nbp                 12\nsg                 47\nal                 46\nsu                 49\nrbc               152\npc                 65\npcc                 4\nba                  4\nbgr                44\nbu                 19\nsc                 17\nsod                87\npot                88\nhemo               52\npcv                70\nwc                105\nrc                130\nhtn                 2\ndm                  2\ncad                 2\nappet               1\npe                  1\nane                 1\nclassification      0\ndtype: int64\n\n\nTerdapat banyak sekali missing value hampir di semua fitur. Untuk mengatasi hal tersebut perlu dilakukan pengisian data terhadap missing value dengan menggunakan mean atau rata-rata\n\n\n1.2.6 Duplikat data\nDuplikat data merujuk pada keberadaan entri atau baris data yang identik atau serupa dalam dataset. Duplikasi data bisa terjadi karena beberapa sebab, seperti kesalahan input, duplikasi data saat penggabungan dataset, atau kesalahan dalam proses pengumpulan data. Identifikasi dan penanganan duplikat data penting dalam analisis data karena bisa memengaruhi hasil secara tidak akurat, serta dapat memengaruhi kebijakan atau keputusan yang diambil berdasarkan data tersebut. Proses penanganan duplikat dapat melibatkan penghapusan baris yang sama atau mengkonsolidasikan informasi dari entri yang duplikat.\n\njumlah_duplikat = df.duplicated().sum()\n\n# Menampilkan jumlah data yang duplikat\nprint(\"Jumlah data yang duplikat:\", jumlah_duplikat)\n\nJumlah data yang duplikat: 0\n\n\nNoted : tidak terdapat beberapa baris data yang sama, sehingga data tersebut tidak perlu dihilangkan untuk menghindari adanya data yang redundan\n\n\n1.2.7 Mengidentifikasi Karakter Khusus\nIdentifikasi karakter khusus adalah proses mengenali dan memahami keberadaan karakter yang tidak umum atau khusus dalam suatu dataset. Karakter khusus dapat termasuk simbol-simbol tertentu, spasi yang tidak terlihat, atau karakter lain yang tidak sesuai dengan format atau tipe data yang diharapkan.\n\nimport pandas as pd\n\n\n# Loop melalui setiap kolom dan cek nilai unik untuk mendeteksi karakter khusus\nfor column in df.columns:\n    unique_values = df[column].unique()\n\n    # Tampilkan nama kolom dan nilai unik yang mengandung karakter khusus\n    for value in unique_values:\n        if isinstance(value, str) and (any(not c.isalnum() and not c.isspace() for c in value) or '\\t' in value):\n            print(f\"Kolom '{column}': Karakter khusus terdeteksi - '{value}'\")\n\nKolom 'pcv': Karakter khusus terdeteksi - ' ?'\nKolom 'pcv': Karakter khusus terdeteksi - ' 43'\nKolom 'wc': Karakter khusus terdeteksi - '  6200'\nKolom 'wc': Karakter khusus terdeteksi - '  8400'\nKolom 'wc': Karakter khusus terdeteksi - '  ?'\nKolom 'rc': Karakter khusus terdeteksi - '5.2'\nKolom 'rc': Karakter khusus terdeteksi - '3.9'\nKolom 'rc': Karakter khusus terdeteksi - '4.6'\nKolom 'rc': Karakter khusus terdeteksi - '4.4'\nKolom 'rc': Karakter khusus terdeteksi - '4.0'\nKolom 'rc': Karakter khusus terdeteksi - '3.7'\nKolom 'rc': Karakter khusus terdeteksi - '3.8'\nKolom 'rc': Karakter khusus terdeteksi - '3.4'\nKolom 'rc': Karakter khusus terdeteksi - '2.6'\nKolom 'rc': Karakter khusus terdeteksi - '2.8'\nKolom 'rc': Karakter khusus terdeteksi - '4.3'\nKolom 'rc': Karakter khusus terdeteksi - '3.2'\nKolom 'rc': Karakter khusus terdeteksi - '3.6'\nKolom 'rc': Karakter khusus terdeteksi - '4.1'\nKolom 'rc': Karakter khusus terdeteksi - '4.9'\nKolom 'rc': Karakter khusus terdeteksi - '2.5'\nKolom 'rc': Karakter khusus terdeteksi - '4.2'\nKolom 'rc': Karakter khusus terdeteksi - '4.5'\nKolom 'rc': Karakter khusus terdeteksi - '3.1'\nKolom 'rc': Karakter khusus terdeteksi - '4.7'\nKolom 'rc': Karakter khusus terdeteksi - '3.5'\nKolom 'rc': Karakter khusus terdeteksi - '6.0'\nKolom 'rc': Karakter khusus terdeteksi - '5.0'\nKolom 'rc': Karakter khusus terdeteksi - '2.1'\nKolom 'rc': Karakter khusus terdeteksi - '5.6'\nKolom 'rc': Karakter khusus terdeteksi - '2.3'\nKolom 'rc': Karakter khusus terdeteksi - '2.9'\nKolom 'rc': Karakter khusus terdeteksi - '2.7'\nKolom 'rc': Karakter khusus terdeteksi - '8.0'\nKolom 'rc': Karakter khusus terdeteksi - '3.3'\nKolom 'rc': Karakter khusus terdeteksi - '3.0'\nKolom 'rc': Karakter khusus terdeteksi - '2.4'\nKolom 'rc': Karakter khusus terdeteksi - '4.8'\nKolom 'rc': Karakter khusus terdeteksi - '  ?'\nKolom 'rc': Karakter khusus terdeteksi - '5.4'\nKolom 'rc': Karakter khusus terdeteksi - '6.1'\nKolom 'rc': Karakter khusus terdeteksi - '6.2'\nKolom 'rc': Karakter khusus terdeteksi - '6.3'\nKolom 'rc': Karakter khusus terdeteksi - '5.1'\nKolom 'rc': Karakter khusus terdeteksi - '5.8'\nKolom 'rc': Karakter khusus terdeteksi - '5.5'\nKolom 'rc': Karakter khusus terdeteksi - '5.3'\nKolom 'rc': Karakter khusus terdeteksi - '6.4'\nKolom 'rc': Karakter khusus terdeteksi - '5.7'\nKolom 'rc': Karakter khusus terdeteksi - '5.9'\nKolom 'rc': Karakter khusus terdeteksi - '6.5'\nKolom 'dm': Karakter khusus terdeteksi - '  no'\nKolom 'dm': Karakter khusus terdeteksi - '  yes'\nKolom 'cad': Karakter khusus terdeteksi - ' no'\nKolom 'classification': Karakter khusus terdeteksi - 'ckd   '\n\n\nNoted : Diperoleh terdapat beberpa kolom yang memiliki karakter khusus tab (‘) pada kolom ’pcv’, ‘wc’, ‘rc’, ‘dm’, dan ‘cad’ dan juga terdapat kesalahan konversi tipe data pada kolom ‘rc’\n\n\n1.2.8 Mengidentifikasi Outlier\nOutlier Pada Data adalah nilai yang berbeda dari yang lain dimana perbedaannya sangat jauh dengan sekumpulan data yang lain dalam satu kolom.Keberadaan Outlier sendiri dinilai dapat mengganggu analisis statistik dan kesimpulan yang diambil dari data karena mereka bisa menyebabkan pergeseran rata-rata atau mengganggu distribusi data secara keseluruhan. Maka dari itu, pada data penyakit ginjal kronis ini perlu dilakukan identifikasi outlier pada data. Untuk menentukan outlier pada data dapat dengan menggunakan metode Local Outlier Factor.\nLOCAL OUTLIER FACTOR\n\nAdalah metode yang digunakan untuk mendeteksi outlier dalam data dengan memperhatikan konteks lokal dari setiap data poin. LOF menghitung seberapa “aneh” atau tidak biasa suatu poin data jika dibandingkan dengan tetangga-tetangganya. Poin yang memiliki LOF tinggi dibandingkan dengan tetangganya dapat dianggap sebagai outlier.\nAdapun tahap-tahp untuk mengidentifikasi outlier pada data dengan menggunakan Local Outlier Factor :\n\nHitung Jarak Antar Data dimana jarak yang dihitung adalah jarak titik yang akan dievaluasi dengan semua titik didalam satu baris. Perhitungan Jarak dilakukan menggunakan perhitungan jarak euclidean. \\[\n\\text{distance}(p, q) = \\sqrt{\\sum_{i=1}^{n}(p_i - q_i)^2}\n\\] dimana : p = titik yang akan dievaluasi q = titik selain titik p\nHitung Kepadatan Lokal Setelah jarak diketahui, maka selanjutnya kepadatan lokal dari titik data tersebut perlu dihitung. Kepadatan lokal dapat dihitung dengan membandingkan jumlah titik-titik tetangga dalam jarak tertentu (radius) terhadap titik data yang sedang dievaluasi. \\[\n\\text{Local Density}(p) = \\frac{\\text{jumlah tetangga dalam radius}}{\\text{jumlah total data}}\n\\]\nHitung Local Reachability Density(LRD) Hitung kepadatan jarak (reachability distance) dari titik data (p) terhadap tetangganya (q). Local Reachability Density dari titik p terhadap tetangga q dihitung sebagai rata-rata dari jarak antara q dan p terhadap tetangga q: \\[\n\\text{reachdist}(p, q) = \\max(\\text{distance}(p, q), \\text{radius})\n\\]\n\n\\[\n\\text{Local Reachability Density}(p) = \\frac{1}{\\text{jumlah tetangga}} \\sum_{q \\in N_{\\text{radius}}(p)} \\frac{\\text{reachdist}(p, q)}{\\text{density}(q)}\n\\]\ndimana: - N radius(p) adalah himpunan tetangga dalam radius tertentu radius dari titik p. - density(q) adalah kepadatan lokal dari tetangga q.\n\nHitung Nilai LOF LOF dari suatu titik data (p) dihitung sebagai rasio dari rata-rata Local Reachability Density dari tetangganya terhadap kepadatan lokalnya sendiri: \\[\n\\text{LOF}(p) = \\frac{1}{\\text{jumlah tetangga}} \\sum_{q \\in N_{\\text{radius}}(p)} \\frac{\\text{Local Reachability Density}(q)}{\\text{Local Reachability Density}(p)}\n\\]\n\ndimana : LOF yang tinggi menunjukkan bahwa titik tersebut memiliki kepadatan lokal yang lebih rendah dibandingkan dengan tetangganya, sehingga cenderung menjadi outlier.\nContoh Kasus, untuk mencari outlier pada data misalkan terdapat tabel seperti dibawah ini:\n\n\n\nX\nY\n\n\n\n\n1\n4\n\n\n2\n3\n\n\n3\n8\n\n\n7\n2\n\n\n5\n9\n\n\n\n\nLangkah 1 : Hitung Jarak Antar Data lalu nilai radius yang diambil adalah 5\n\n\n\n\nX\nY\nJarak\n\n\n\n\n1\n4\n1,41 ; 4,47 ; 4,47\n\n\n2\n3\n1,41 ; 3,16\n\n\n3\n8\n4,47\n\n\n5\n2\n4,47 ; 3,16 ; 4,24\n\n\n8\n5\n4,24\n\n\n\n\nLangkah 2 : Hitung jumlah tetangga dalam radius 5\n\n\n\n\nX\nY\nJumlah Tetangga\n\n\n\n\n1\n4\n3\n\n\n2\n3\n2\n\n\n3\n8\n1\n\n\n5\n2\n3\n\n\n8\n5\n1\n\n\n\n\nLangkah 3 : Hitung Local Reachability Density\n\n\n\n\nX\nY\nJarak\n\n\n\n\n1\n4\n(1,41 + 4,47 + 4,47) / 3 = 3,45\n\n\n2\n3\n(1,41 + 3,16) /2 = 2,285\n\n\n3\n8\n4,47\n\n\n5\n2\n(4,47 + 3,16 + 4,24) / 3 = 3,95\n\n\n8\n5\n4,24\n\n\n\n\nLangkah 4 : Menghitung nilai LOF data\n\n\n\n\nX\nY\nLOF\n\n\n\n\n1\n4\n(1/3,45) x ((2,285 + 4,47 + 3,95) / 3) = 1,03\n\n\n2\n3\n(1/2,285) x ((3,45 + 3,95) / 2) = 1,61\n\n\n3\n8\n(1/4,47) x ((3,45)) = 0,77\n\n\n5\n2\n(1/3,95) x ((3,45 + 2,285 + 4,24) / 3) = 0,83\n\n\n8\n5\n(1/4,24) x ((3,95)) = 0.936\n\n\n\nDengan begitu, nilai yang berkemungkinan menjadi outlier adalah baris 2 dan baris 1\nInter Pretasi Local Outlier Factor :\n\nJika LOF &gt; 1, itu menunjukkan bahwa kepadatan lokal dari titik p lebih rendah daripada rata-rata kepadatan lokal dari tetangganya. Artinya, titik tersebut memiliki sifat yang “aneh” atau berbeda dari lingkungan sekitarnya dan cenderung menjadi outlier.\nJika LOF ≈ 1, itu menunjukkan bahwa kepadatan lokal dari titik p mirip dengan rata-rata kepadatan lokal tetangganya.\nJika LOF &lt; 1, itu menunjukkan bahwa kepadatan lokal dari titik p lebih tinggi daripada rata-rata kepadatan lokal dari tetangganya, sehingga cenderung menjadi titik yang tidak aneh.\n\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import LocalOutlierFactor\nimport numpy as np\nimport pandas as pd\n\n\n# Membagi data menjadi numerik dan kategorikal\nnumerical_cols = df.select_dtypes(include=['int', 'float']).columns\ncategorical_cols = df.select_dtypes(include='object').columns\n\n# Menggunakan SimpleImputer untuk mengisi nilai yang hilang dengan mean (dapat disesuaikan)\nimputer = SimpleImputer(strategy='mean')\ndf[numerical_cols] = imputer.fit_transform(df[numerical_cols])\n\n# Label Encoding untuk kolom kategorikal\nfrom sklearn.preprocessing import LabelEncoder\n\nlabel_encoder = LabelEncoder()\ndf[categorical_cols] = df[categorical_cols].apply(lambda col: label_encoder.fit_transform(col))\n\n# Menggabungkan kolom numerik dan kategorikal\nselected_data = df[numerical_cols.union(categorical_cols)]\n\n# Normalisasi df numerik\nscaler = StandardScaler()\nselected_data[numerical_cols] = scaler.fit_transform(selected_data[numerical_cols])\n\n# Membuat model LOF\nclf = LocalOutlierFactor(n_neighbors=20)  # Jumlah tetangga yang digunakan\noutlier_scores = clf.fit_predict(selected_data)\n\n# Menampilkan indeks outlier\noutlier_indices = np.where(outlier_scores == -1)[0]\nprint(\"Indeks outlier:\", outlier_indices)\nprint(\"Jumlah outlier:\", len(outlier_indices))\n\nIndeks outlier: [ 21  61  65  66  73  88 106 141 148 175 197 214 230 235 249 255 295 302\n 349]\nJumlah outlier: 19\n\n\nNoted : Terdapat outlier berjumlah 19 outlier.\nKesimpulan : 1. Data memiliki missing values 2. Data tidak memiliki data redundan 3. Terdapat karakter khusus pada data dan kesalahan konversi tipe data 3. Data memiliki outlier berjumlah 19 4. Perbandingan proporsi data tiap target tidak terlalu jauh sehingga tidak perlu di seimbangkan menggunakan metode UnderSampling"
  },
  {
    "objectID": "Chronic_Kidney_Disease.html#data-preprocessing",
    "href": "Chronic_Kidney_Disease.html#data-preprocessing",
    "title": "1  ——————————– TUGAS PROYEK SAINS DATA ——————————-",
    "section": "1.3 3. Data Preprocessing",
    "text": "1.3 3. Data Preprocessing\nTahap preprocessing adalah tahapan untuk mempersiapkan data sebelum dilakukan pembuatan model. Pada tahap preprocessing, data akan dibersihkan, diubah, dan disesuaikan agar data sesuai dengan kebutuhan pada model machine learning yang akan digunakan. Tahap preprocessing merupakan langkah-langkah untuk membersihkan dan menyiapkan data sebelum memasukkan ke dalam model.\n\nSetelah memahami data, akan dilakukan tahap preprocessing untuk menangani masalah pada data yang sudah didefinisikan pada Data Understanding, yakni. 1. Menghapus karakter khusus dan mengubah kesalahan konversi tipe data 2. Mengisi data missing value 3. menghapus Outlier\nSetelah data siap, akan dilakukan : 1. Skoring tiap fitur kembali 2. Normalisasi Data 3. Eksplorasi Model\n\nimport pandas as pd\n\ndf = pd.read_csv('kidney_disease.csv')\ndf.head(5)\n\n\n  \n    \n\n\n\n\n\n\nid\nage\nbp\nsg\nal\nsu\nrbc\npc\npcc\nba\n...\npcv\nwc\nrc\nhtn\ndm\ncad\nappet\npe\nane\nclassification\n\n\n\n\n0\n0\n48.0\n80.0\n1.020\n1.0\n0.0\nNaN\nnormal\nnotpresent\nnotpresent\n...\n44\n7800\n5.2\nyes\nyes\nno\ngood\nno\nno\nckd\n\n\n1\n1\n7.0\n50.0\n1.020\n4.0\n0.0\nNaN\nnormal\nnotpresent\nnotpresent\n...\n38\n6000\nNaN\nno\nno\nno\ngood\nno\nno\nckd\n\n\n2\n2\n62.0\n80.0\n1.010\n2.0\n3.0\nnormal\nnormal\nnotpresent\nnotpresent\n...\n31\n7500\nNaN\nno\nyes\nno\npoor\nno\nyes\nckd\n\n\n3\n3\n48.0\n70.0\n1.005\n4.0\n0.0\nnormal\nabnormal\npresent\nnotpresent\n...\n32\n6700\n3.9\nyes\nno\nno\npoor\nyes\nyes\nckd\n\n\n4\n4\n51.0\n80.0\n1.010\n2.0\n0.0\nnormal\nnormal\nnotpresent\nnotpresent\n...\n35\n7300\n4.6\nno\nno\nno\ngood\nno\nno\nckd\n\n\n\n\n\n5 rows × 26 columns\n\n    \n\n  \n    \n\n  \n    \n  \n    \n\n  \n\n    \n  \n\n\n\n  \n\n\n    \n        \n    \n\n  \n\n\n\n  \n\n    \n  \n\n\n\n# Rincian dataset (banyak data dan kolom)\n\nprint(\"Banyaknya data : \", df.shape[0])\nprint(\"Banyaknya kolom : \", df.shape[1])\n\nBanyaknya data :  400\nBanyaknya kolom :  26\n\n\n\n1.3.1 Cleaning Data\nPembersihan data, atau data cleaning, adalah proses identifikasi, koreksi, atau penghapusan kesalahan dan ketidaksesuaian dalam dataset. Tujuan dari cleaning data adalah untuk memastikan bahwa data yang digunakan dalam analisis atau pemodelan adalah akurat, konsisten, dan siap digunakan.\nMenghapus karakter khusus dan mengubah kesalahan konversi tipe data\nMenghapus karakter tambahan([’]) dan spasi yang terdapat pada isi data tiap fitur\n\nimport pandas as pd\n\n# Gantilah dengan path yang sesuai ke file CSV penyakit ginjal kronis\n\n# Loop melalui kolom-kolom yang perlu dihandle\ncolumns_to_handle = ['pcv', 'wc', 'rc', 'dm', 'cad', 'classification']\n\nfor column in columns_to_handle:\n    # Mengganti '\\t' dan spasi ekstra dengan string kosong\n    df[column] = df[column].replace(r'\\t', '', regex=True).str.strip()\n\n# Menangani karakter khusus pada kolom 'classification' (menghapus spasi ekstra)\ndf['classification'] = df['classification'].str.strip()\n\n# Menangani karakter khusus pada kolom 'classification' (menghapus 'ckd\\t')\ndf['classification'] = df['classification'].replace('ckd\\t', 'ckd', regex=True)\n\n# Konversi tipe df kolom 'rc' ke numerik, menggantikan nilai yang tidak dapat diubah\ndf['rc'] = pd.to_numeric(df['rc'], errors='coerce')\n\nfor column in columns_to_handle:\n    print(df[column].unique())\n\n\n['44' '38' '31' '32' '35' '39' '36' '33' '29' '28' nan '16' '24' '37' '30'\n '34' '40' '45' '27' '48' '?' '52' '14' '22' '18' '42' '17' '46' '23' '19'\n '25' '41' '26' '15' '21' '43' '20' '47' '9' '49' '50' '53' '51' '54']\n['7800' '6000' '7500' '6700' '7300' nan '6900' '9600' '12100' '4500'\n '12200' '11000' '3800' '11400' '5300' '9200' '6200' '8300' '8400' '10300'\n '9800' '9100' '7900' '6400' '8600' '18900' '21600' '4300' '8500' '11300'\n '7200' '7700' '14600' '6300' '7100' '11800' '9400' '5500' '5800' '13200'\n '12500' '5600' '7000' '11900' '10400' '10700' '12700' '6800' '6500'\n '13600' '10200' '9000' '14900' '8200' '15200' '5000' '16300' '12400'\n '10500' '4200' '4700' '10900' '8100' '9500' '2200' '12800' '11200'\n '19100' '?' '12300' '16700' '2600' '26400' '8800' '7400' '4900' '8000'\n '12000' '15700' '4100' '5700' '11500' '5400' '10800' '9900' '5200' '5900'\n '9300' '9700' '5100' '6600']\n[5.2 nan 3.9 4.6 4.4 5.  4.  3.7 3.8 3.4 2.6 2.8 4.3 3.2 3.6 4.1 4.9 2.5\n 4.2 4.5 3.1 4.7 3.5 6.  2.1 5.6 2.3 2.9 2.7 8.  3.3 3.  2.4 4.8 5.4 6.1\n 6.2 6.3 5.1 5.8 5.5 5.3 6.4 5.7 5.9 6.5]\n['yes' 'no' nan]\n['no' 'yes' nan]\n['ckd' 'notckd']\n\n\nMengubah kesalahan konversi tipe data\n\ncolumns_to_convert = ['pcv', 'wc', 'rc']\nfor col in columns_to_convert:\n    df[col] = pd.to_numeric(df[col], errors='coerce')\n    print(df[col].unique())\n\n\n\n[44. 38. 31. 32. 35. 39. 36. 33. 29. 28. nan 16. 24. 37. 30. 34. 40. 45.\n 27. 48. 52. 14. 22. 18. 42. 17. 46. 23. 19. 25. 41. 26. 15. 21. 43. 20.\n 47.  9. 49. 50. 53. 51. 54.]\n[ 7800.  6000.  7500.  6700.  7300.    nan  6900.  9600. 12100.  4500.\n 12200. 11000.  3800. 11400.  5300.  9200.  6200.  8300.  8400. 10300.\n  9800.  9100.  7900.  6400.  8600. 18900. 21600.  4300.  8500. 11300.\n  7200.  7700. 14600.  6300.  7100. 11800.  9400.  5500.  5800. 13200.\n 12500.  5600.  7000. 11900. 10400. 10700. 12700.  6800.  6500. 13600.\n 10200.  9000. 14900.  8200. 15200.  5000. 16300. 12400. 10500.  4200.\n  4700. 10900.  8100.  9500.  2200. 12800. 11200. 19100. 12300. 16700.\n  2600. 26400.  8800.  7400.  4900.  8000. 12000. 15700.  4100.  5700.\n 11500.  5400. 10800.  9900.  5200.  5900.  9300.  9700.  5100.  6600.]\n[5.2 nan 3.9 4.6 4.4 5.  4.  3.7 3.8 3.4 2.6 2.8 4.3 3.2 3.6 4.1 4.9 2.5\n 4.2 4.5 3.1 4.7 3.5 6.  2.1 5.6 2.3 2.9 2.7 8.  3.3 3.  2.4 4.8 5.4 6.1\n 6.2 6.3 5.1 5.8 5.5 5.3 6.4 5.7 5.9 6.5]\n\n\n\n\n1.3.2 Mengisi data missing value\nMelakukan transformasi data guna mempermudah untuk pengisian missing value.\nAdapun ketentuannya sebagai berikut:\n- rbc\n  - normal = 1\n  - abnormal = 0\n- pc\n  - normal = 1\n  - abnormal = 0\n- pcc\n  - present = 1\n  - notpresent = 0\n- ba\n  - present = 1\n  - notpresent = 0\n- htn\n  - yes = 1\n  - no = 0\n- dm\n  - yes = 1\n  - no = 0\n- cad\n  - yes = 1\n  - no = 0\n- appet\n  - good = 1\n  - poor = 0\n- pe\n  - yes = 1\n  - no = 0\n- ane\n  - yes = 1\n  - no = 0\n- classification\n  - ckd = 1\n  - notckd = 0\n\n# Daftar kolom yang perlu diubah sesuai dengan aturan Anda\ncolumns_to_convert = ['rbc', 'pc', 'pcc', 'ba', 'htn', 'dm', 'cad', 'appet', 'pe', 'ane', 'classification']\n\n# Aturan konversi sesuai dengan yang Anda sebutkan\nconversion_rules = {\n    'rbc': {'normal': 1, 'abnormal': 0},\n    'pc': {'normal': 1, 'abnormal': 0},\n    'pcc': {'present': 1, 'notpresent': 0},\n    'ba': {'present': 1, 'notpresent': 0},\n    'htn': {'yes': 1, 'no': 0},\n    'dm': {'yes': 1, 'no': 0},\n    'cad': {'yes': 1, 'no': 0},\n    'appet': {'good': 1, 'poor': 0},\n    'pe': {'yes': 1, 'no': 0},\n    'ane': {'yes': 1, 'no': 0},\n    'classification': {'ckd': 1, 'notckd': 0}\n}\n\n# Mengubah data berdasarkan aturan yang telah ditentukan\ndf[columns_to_convert] = df[columns_to_convert].replace(conversion_rules)\n\n# Menampilkan data setelah konversi\nprint(df[columns_to_convert])\n\n     rbc   pc  pcc   ba  htn   dm  cad  appet   pe  ane  classification\n0    NaN  1.0  0.0  0.0  1.0  1.0  0.0    1.0  0.0  0.0               1\n1    NaN  1.0  0.0  0.0  0.0  0.0  0.0    1.0  0.0  0.0               1\n2    1.0  1.0  0.0  0.0  0.0  1.0  0.0    0.0  0.0  1.0               1\n3    1.0  0.0  1.0  0.0  1.0  0.0  0.0    0.0  1.0  1.0               1\n4    1.0  1.0  0.0  0.0  0.0  0.0  0.0    1.0  0.0  0.0               1\n..   ...  ...  ...  ...  ...  ...  ...    ...  ...  ...             ...\n395  1.0  1.0  0.0  0.0  0.0  0.0  0.0    1.0  0.0  0.0               0\n396  1.0  1.0  0.0  0.0  0.0  0.0  0.0    1.0  0.0  0.0               0\n397  1.0  1.0  0.0  0.0  0.0  0.0  0.0    1.0  0.0  0.0               0\n398  1.0  1.0  0.0  0.0  0.0  0.0  0.0    1.0  0.0  0.0               0\n399  1.0  1.0  0.0  0.0  0.0  0.0  0.0    1.0  0.0  0.0               0\n\n[400 rows x 11 columns]\n\n\nMengisi missing value dengan rata-rata\nBerikut merupakan cara mengisi missing value secara manual\nRumus\n\\[\\text{Nilai yang akan diisi} = \\frac{\\text{Jumlah nilai pada kelas tertentu}}{\\text{Total nilai pada kelas tertentu}} \\times \\text{Total nilai yang ada pada kolom} \\]\nData Awal\n\n\n\nAtribut\nKelas\n\n\n\n\n20\nYes\n\n\n25\nNo\n\n\nNaN\nYes\n\n\n30\nYes\n\n\nNaN\nNo\n\n\nNaN\nNo\n\n\n\nPerhitungan\n\nJumlah ‘Yes’ pada Atribut: \\[ 20 + \\text{NaN} + 30 = 50 \\]\nJumlah ‘No’ pada Atribut: \\[ 25 + \\text{NaN} + \\text{NaN} = 25 \\]\nTotal Atribut sebelum diisi: \\[ 20 + 25 + \\text{NaN} + 30 + \\text{NaN} + \\text{NaN} = \\text{Total Atribut Sebelum} = 75 \\]\nRumus untuk mengisi missing value di Atribut:\n\nUntuk kelas yes \\[\\text{Nilai yang akan diisi} = \\frac{50}{50} \\times 75\\]\nUntuk kelas no \\[\\text{Nilai yang akan diisi} = \\frac{50}{25} \\times 75\\]\n\nPerhitungan:\n\nUntuk kelas yes \\[\\text{Nilai yang akan diisi} = \\frac{50}{50} \\times 75 = 75\\]\nUntuk kelas no \\[\\text{Nilai yang akan diisi} = \\frac{50}{25} \\times 75 = 150\\]\n\n\nDiperoleh untuk baris yang memiliki kelas yes akan diisi dengan nilai 75 dan baris yang memliki kelas no akan diisi dengan 150:\nData Setelah Diisi\n\n\n\nAtribut\nKelas\n\n\n\n\n20\nYes\n\n\n25\nNo\n\n\n75\nYes\n\n\n30\nYes\n\n\n150\nNo\n\n\n150\nNo\n\n\n\nUntuk implementasinya disini akan menggunakan SimpleImputer dalam mengisi missing value pada data ini. SimpleImputer adalah sebuah kelas dalam pustaka scikit-learn yang menyediakan fungsionalitas untuk mengisi nilai yang hilang dalam dataset. Pada library ini terdapat 4 strategi yang dapat digunakan dalam pengisian missing value nantinya, yaitu sebagai berikut:\n\nmean: Mengisi nilai yang hilang dengan rata-rata dari nilai yang ada pada kolom.\nmedian: Mengisi nilai yang hilang dengan nilai tengah dari nilai yang ada pada kolom.\nmost_frequent: Mengisi nilai yang hilang dengan nilai yang paling sering muncul pada kolom.\nconstant: Mengisi nilai yang hilang dengan nilai konstan yang ditentukan sebelumnya.\n\nNoted : Strategi yang akan digunakan pada tahap ini yaitu mean.\n\nfrom sklearn.impute import SimpleImputer\n\n# Daftar kolom dengan missing values\ncolumns_with_missing = df.columns[df.isnull().any()]\n\n# Membuat objek SimpleImputer dengan strategi 'mean'\nimputer = SimpleImputer(strategy='mean')\n\n# Mengisi missing values dengan mean berdasarkan kelasnya\nfor col in columns_with_missing:\n    # Pisahkan data berdasarkan kelas target\n    for classification_value in df['classification'].unique():\n        # Ambil subset data untuk kelas tertentu\n        subset_data = df[df['classification'] == classification_value]\n\n        # Pilih kolom yang sesuai\n        subset_data_col = subset_data[[col]]\n\n        # Menggunakan SimpleImputer untuk mengisi missing value dengan mean\n        imputed_values = imputer.fit_transform(subset_data_col)\n\n        # Gabungkan kembali hasil imputasi ke DataFrame utama\n        df.loc[df['classification'] == classification_value, col] = imputed_values\n\n# Cetak informasi dataset setelah mengisi missing value dengan mean berdasarkan kelasnya\nprint(df.info())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 400 entries, 0 to 399\nData columns (total 26 columns):\n #   Column          Non-Null Count  Dtype  \n---  ------          --------------  -----  \n 0   id              400 non-null    int64  \n 1   age             400 non-null    float64\n 2   bp              400 non-null    float64\n 3   sg              400 non-null    float64\n 4   al              400 non-null    float64\n 5   su              400 non-null    float64\n 6   rbc             400 non-null    float64\n 7   pc              400 non-null    float64\n 8   pcc             400 non-null    float64\n 9   ba              400 non-null    float64\n 10  bgr             400 non-null    float64\n 11  bu              400 non-null    float64\n 12  sc              400 non-null    float64\n 13  sod             400 non-null    float64\n 14  pot             400 non-null    float64\n 15  hemo            400 non-null    float64\n 16  pcv             400 non-null    float64\n 17  wc              400 non-null    float64\n 18  rc              400 non-null    float64\n 19  htn             400 non-null    float64\n 20  dm              400 non-null    float64\n 21  cad             400 non-null    float64\n 22  appet           400 non-null    float64\n 23  pe              400 non-null    float64\n 24  ane             400 non-null    float64\n 25  classification  400 non-null    int64  \ndtypes: float64(24), int64(2)\nmemory usage: 81.4 KB\nNone\n\n\n\n\n1.3.3 Menghapus Data Outlier\n\n# Menghilangkan baris data yang mengandung outlier\ndf_cleaned = df.drop(outlier_indices)\n\n# Menampilkan informasi setelah menghilangkan outlier\nprint(\"Jumlah baris sebelum menghilangkan outlier:\", len(df))\nprint(\"Jumlah baris setelah menghilangkan outlier:\", len(df_cleaned))\nprint(\"Informasi DataFrame setelah menghapus outlier:\")\nprint(df_cleaned.info())\n\nJumlah baris sebelum menghilangkan outlier: 400\nJumlah baris setelah menghilangkan outlier: 381\nInformasi DataFrame setelah menghapus outlier:\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nInt64Index: 381 entries, 0 to 399\nData columns (total 26 columns):\n #   Column          Non-Null Count  Dtype  \n---  ------          --------------  -----  \n 0   id              381 non-null    int64  \n 1   age             381 non-null    float64\n 2   bp              381 non-null    float64\n 3   sg              381 non-null    float64\n 4   al              381 non-null    float64\n 5   su              381 non-null    float64\n 6   rbc             381 non-null    float64\n 7   pc              381 non-null    float64\n 8   pcc             381 non-null    float64\n 9   ba              381 non-null    float64\n 10  bgr             381 non-null    float64\n 11  bu              381 non-null    float64\n 12  sc              381 non-null    float64\n 13  sod             381 non-null    float64\n 14  pot             381 non-null    float64\n 15  hemo            381 non-null    float64\n 16  pcv             381 non-null    float64\n 17  wc              381 non-null    float64\n 18  rc              381 non-null    float64\n 19  htn             381 non-null    float64\n 20  dm              381 non-null    float64\n 21  cad             381 non-null    float64\n 22  appet           381 non-null    float64\n 23  pe              381 non-null    float64\n 24  ane             381 non-null    float64\n 25  classification  381 non-null    int64  \ndtypes: float64(24), int64(2)\nmemory usage: 80.4 KB\nNone\n\n\nSimpan data yang sudah di transformasi dan sudah tidak ada missing value\n\n# Menyimpan DataFrame ke dalam file CSV\ndf_cleaned.to_csv('data_baru_bangetz.csv', index=False)\n\n\ndata =  pd.read_csv('data_baru_bangetz.csv')\nfitur = data.drop(columns=['id','classification'])\ntarget = data['classification']\n\n\ntarget.value_counts()\n\n1    235\n0    146\nName: classification, dtype: int64\n\n\n\n\n1.3.4 RANKING SETIAP FITUR DALAM DATA\nUntuk memilih fitur terbaik dapat dengan me-renking fitur-fitur didalm dataset dengan mencari nilai mutual information setiap fitur agar dapat dibandingkan diurutkan dengan fitur lainnya. Padaproyek ini digunakan metode SelectKBest dengan mencari nilai mutual information dari setiap fitur.\nMUTUAL INFORMATION\nMutual information (MI) adalah metrik yang berguna dalam pemilihan fitur karena mengukur seberapa banyak informasi yang saling terkait antara fitur (variabel independen) dengan variabel target (variabel dependen). Dalam konteks pemilihan fitur, kita ingin mempertahankan fitur-fitur yang memiliki hubungan yang kuat atau tinggi dalam menjelaskan variabel target.\nRumus Mutual Information (MI) between X and Y:\n\\[\n\\text{MI}(X;Y) = \\sum_{x \\in X} \\sum_{y \\in Y} p(x, y) \\log \\left(\\frac{p(x, y)}{p(x) \\cdot p(y)}\\right)\n\\]\nDimana: - MI(X;Y) adalah mutual information antara variabel X dan Y. - p(x,y) adalah probabilitas bersama dari X=x dan Y=y. - p(x) adalah probabilitas margina X=x. - p(y) adalah probabilitas margina Y=y.\nDari tahap ini dihasilkan rangking dari setiap kolom atau fitur sehingga dapat mengetahui fitur-fitur yang memiliki ciri khas penting untuk data red wine itu sendiri. Pada tahap skenario percobaan nantinya akan dipilih fitur-fitur yang memiliki nilai mutual information tertinggi. Untuk memilih fitur-fitur yang terbaik dapat dimulai dengan menghapus fitur yang memiliki nilai mutual information paling rendah lalu skenario bergeser ke kiri dimana fitur yang dihapus yaitu fitur dengan mutual information terendah nomer 2 dan paling rendah. pemilihan fitur terus dilakukan pada skenario percobaan hingga mencapai akurasi tertinggi.\nContoh Kasus untuk mengurutkan kolom dengan mutual information paling tinggi hingga terendah, di berikan tabel berikut :\n\n\n\nID\nVariabel_1\nVariabel_2\nVariabel_Target\n\n\n\n\n1\n2\n3\nb\n\n\n2\n1\n2\na\n\n\n3\n3\n1\na\n\n\n4\n2\n2\nb\n\n\n5\n1\n3\na\n\n\n\n\nLangkah 1 : Hitung distribusi probabilitas\n\nUntuk Variabel_Target: &gt; - P(Target=a) = 3/5 &gt; - P(Target=b) = 2/5\nUntuk Variabel_1: &gt; - P(Variabel_1=1) = 2/5 &gt; - P(Variabel_1=2) = 2/5 &gt; - P(Variabel_1=3) = 1/5\nUntuk Variabel_2:\n\n\nP(Variabel_2=1) = 1/5\nP(Variabel_2=2) = 2/5\nP(Variabel_2=3) = 2/5\n\n\n\nLangkah 2 : Hitung Entropi Entropi(variabel_Target) = - (3/5) * log2(3/5) - (2/5) * log2(2/5) ≈ 0.971\n\nEntropi(Variabel_1) = - (2/5) * log2(2/5) - (2/5) * log2(2/5) - (1/5) * log2(1/5) ≈ 1.571\nEntropi(Variabel_2) = - (1/5) * log2(1/5) - (2/5) * log2(2/5) - (2/5) * log2(2/5) ≈ 1.571\n\nLangkah 3 : Hitung Conditional Entropi\n\nUntuk setiap nilai Variabel_1, hitung Entropi(Target|Variabel_1).\nVariabel_1\nConditional_Entropy(Target | Variabel_1) = P(Variabel_1=1) * Entropi(Target|Variabel_1=1) + P(Variabel_1=2) * Entropi(Target|Variabel_1=2) + P(Variabel_1=3) * Entropi(Target|Variabel_1=3)\nEntropi(Target|Variabel_1=1) = - (1/2) * log2(1/2) - (1/2) * log2(1/2) = 1.0\nEntropi(Target|Variabel_1=2) = - (1/1) * log2(1/1) - (1/1) * log2(1/1) = 0.0\nEntropi(Target|Variabel_1=3) = - (1/1) * log2(1/1) = 0.0\nConditional_Entropy(Target | Variabel_1) = (2/5)×1.0+(2/5)×0.0+(1/5)×0.0\nConditional_Entropy(Target | Variabel_1) = 0.4\nVariabel_2\nConditional_Entropy(Target | Variabel_2) = P(Variabel_2=1) * Entropi(Target|Variabel_2=1) + P(Variabel_2=2) * Entropi(Target|Variabel_2=2) + P(Variabel_2=3) * Entropi(Target|Variabel_2=3)\nEntropi(Target | Variabel_2=1) = - (1) * log2(1) = 0\nEntropi(Target | Variabel_2=2) = - (0.5) * log2(0.5) - (0.5) * log2(0.5) = 1.0\nEntropi(Target | Variabel_2=3) = - (0.5) * log2(0.5) - (0.5) * log2(0.5) = 1.0\nConditional_Entropy(Target | Variabel_2) = (1/5) * 0 + (2/5) * 1.0 + (2/5) * 1.0 = 0.8\n\nLangkah 4 : Hitung Mutual Information\n\nMutual_Information(Variabel_1;Target) = 0.971 - 0.4 = 0.571\nMutual_Information(Variabel_2;Target) = 0.971 - 0.8 = 0.171\nDengan begitu variabel yang lebih berpengaruh adalah Variabel_1 dari Variabel_2\n\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import mutual_info_classif\nimport numpy as np\n\nselector = SelectKBest(score_func=mutual_info_classif, k='all')\nX_new = selector.fit_transform(fitur,target)\nscores = selector.scores_\n\nfeature_scores = selector.scores_\nfeature_names = ['age', 'bp', 'sg', 'al', 'su', 'rbc', 'pc', 'pcc', 'ba', 'bgr',\n       'bu', 'sc', 'sod', 'pot', 'hemo', 'pcv', 'wc', 'rc', 'htn', 'dm', 'cad',\n       'appet', 'pe', 'ane']\n\n# Sort the feature scores in descending order\nsorted_indices = feature_scores.argsort()[::-1]\n\n# Get the sorted feature scores and names\nsorted_scores = feature_scores[sorted_indices]\nsorted_feature_names = [feature_names[i] for i in sorted_indices]\n\n# Plot the feature importances\nplt.figure(figsize=(12, 6))\nplt.bar(range(len(sorted_feature_names)), sorted_scores)\nplt.xticks(range(len(sorted_feature_names)), sorted_feature_names, rotation=90)\nplt.xlabel('Features')\nplt.ylabel('Information Gain')\nplt.title('Feature Importance (Information Gain)')\nplt.show()\n\n\n\n\nBerdasarkan skenario percobaan diperoleh fitur terbaik yang akan digunakan dalam klasifikasi ini adalah sebagai berikut:\n\n\nhemo\npcv\nrc\nsc\nsg\nal\nrbc\nsod\npot\nhtn\npc\nbgr\nwc\nbu\ndm\nbp\nappet\nsu\npcc\n\n\n\n\n1.3.5 Split Data\nSplit Data dilakukan dengan menggunakan fitur terbaik yang sudah dipilih sebelumnya.\n\nfrom sklearn.model_selection import train_test_split\n\n#melakukan drop untuk fitur yang tidak digunakan\nfitur = data.drop(columns=['id','age','cad','pe','ane','ba','classification'])\ntarget = data['classification']\n\n# melakukan pembagian dataset, dataset dibagi menjadi 80% data training dan 20% data testing\nfitur_train, fitur_test, target_train, target_test = train_test_split(fitur, target, test_size = 0.2, random_state=42)\n\n\n\n1.3.6 Normalisasi Data\nNormalisasi Data adalah salah satu proses dalam pre-processing data untuk mengatur dataset agar memenuhi standar tertentu. Data perlu dilakukan agar dapat mengurangi kemungkinan terjadinya redundansi data. Selain itu, normalisasi dagunakan untuk membantu menghindari anomali dalam pengolahan data dan memungkinkan desain basis data yang lebih efisien.\nZSCORE\n\nPengertian\nMetode StandardScaler adalah salah satu teknik normalisasi yang umum digunakan dalam pengolahan data. Tujuannya adalah untuk menyesuaikan distribusi data agar memiliki mean (rata-rata) nol dan standar deviasi satu. Ini berguna saat bekerja dengan algoritma yang sensitif terhadap skala dan asumsi dasar bahwa data terdistribusi normal atau mendekati distribusi normal.\nProses normalisasi menggunakan StandardScaler melibatkan dua langkah utama:\n\nMenghitung Mean dan Standar Deviasi: Pertama, perhitungan rata-rata (mean) dan standar deviasi dari setiap fitur (kolom) dalam data dilakukan.\nTransformasi Data: Setelah mendapatkan mean dan standar deviasi, nilai dari setiap fitur dikurangi dengan mean dari fitur tersebut, kemudian hasilnya dibagi dengan standar deviasi fitur tersebut. Proses ini dilakukan untuk setiap nilai dalam setiap fitur.\n\nRumus Standard Scaler\n\\[ X' = \\frac{X - mean(X)}{std(X)} \\] Dimana : - X adalah nilai asli dari suatu kolom/fitur - mean(X) adalah nilai rata-rata dari setiap kolom - std(X) adalah nilai standard deviasi dari setiap kolom - X’ adalah nilai X yang telah dinormalisasi.\nBerikut cara menerapkan metode Standar Sclaing ini untuk melakukan normalisasi data : - Pertama perlu disiapkan tabel yang akan dilakukan normalisasi\n\n\n\nX\nX`\n\n\n\n\n12\n0\n\n\n18\n0\n\n\n35\n0\n\n\n28\n0\n\n\n25\n0\n\n\n\n\nSetelah itu, hitung standar deviasi dan rata-rata di kolom tersebut. Diketahui : &gt; - Standard Deviasi pada kolom X = 8.905055 &gt; - Rata-rata dalam kolom X = 23,6\nSetelah nilai standard deviasi dan rata-rata diketahui maka selanjutnya mulai melakukan normalisasi dengan menghitung X` seperti berikut:\n\n\n\n\nX\nX`\n\n\n\n\n12\n(12 - 23,6) / (8.905055)\n\n\n18\n(18 - 23,6) / (8.905055)\n\n\n35\n(35 - 23,6) / (8.905055)\n\n\n18\n(28 - 23,6) / (8.905055)\n\n\n25\n(25 - 23,6) / (8.905055)\n\n\n\n\nDengan begitu dapat diketahui nilai pada kolom X setelah normalisasi (X`) adalah seperti berikut:\n\n\n\n\nX\nX`\n\n\n\n\n12\n-1.30\n\n\n18\n-0.63\n\n\n35\n1.28\n\n\n18\n0.49\n\n\n25\n0.16\n\n\n\n\nimport pickle\nfrom sklearn.preprocessing import StandardScaler\n\n# menentukan lokasi file pickle akan disimpan\npath = 'zscore_scaler_ckd.pkl'\n\n# membuat dan melatih objek StandardScaler\nzscore_scaler = StandardScaler()\nzscore_scaler.fit(fitur_train)\n\n# menyimpan model ke dalam file pickle\nwith open(path, 'wb') as file:\n    pickle.dump(zscore_scaler, file)\n\n# memanggil kembali model normalisasi zscore dari file pickle\nwith open(path, 'rb') as file:\n    zscore_scaler = pickle.load(file)\n\n# menerapkan normalisasi zscore pada data training\nzscore_training = zscore_scaler.transform(fitur_train)\n\n# menerapkan normalisasi zscore pada data testing\nzscore_testing = zscore_scaler.transform(fitur_test)\n\nMINMAX\n\nPengertian\nMinMax Scaling adalah salah satu teknik untuk melakukan normalisasi pada data dengan merubah nilai-nilai dalam kumpulan data ke dalam rentang tertentu, biasanya antara 0 dan 1. Tujuan utamanya adalah untuk menjaga skala relatif antarfitur agar tidak mendominasi satu sama lain.\nProses Min-Max Scaling dilakukan dengan langkah-langkah berikut:\n\nIdentifikasi Rentang: Tentukan rentang nilai yang ingin Anda gunakan. Biasanya, dalam Min-Max Scaling, rentang nilai yang dipilih adalah 0 hingga 1, tetapi ini bisa disesuaikan tergantung pada kasus penggunaan.\nHitung Nilai Minimum dan Maksimum: Tentukan nilai minimum (min) dan nilai maksimum (max) dari setiap fitur dalam kumpulan data yang akan dinormalisasi.\nNormalisasi: Gunakan formula rumusn Min-Max Scaling untuk mengubah nilai-nilai dalam rentang yang ditentukan.\n\nRumus Minmax Scaler\n\\[ X' = \\frac{X - min}{max - min} \\]\nDimana : - X adalah nilai asli dari suatu kolom/fitur - min adalah nilai minimum dari suatu kolom/fitur dalam dataset - max adalah nilai maximum dari suatu kolom/fitur dalam dataset - X’ adalah nilai X yang telah dinormalisasi.\nBerikut Contoh Penggunaan minmax pada data, sebagai berikut: - Terdapat sebuah tabel dengan kolom X, seperti berikut:\n\n\n\nX\nX`\n\n\n\n\n2\n0\n\n\n4\n0\n\n\n3\n0\n\n\n10\n0\n\n\n\n\nUntuk melakukan normalisasi dengan Min-Max Scaling, maka perlu diidentifikasi nilai tertingggi dan terendah pada kolom. Deketahui : &gt; - Nilai terendah pada kolom X (min) = 2 &gt; - Nilai tertinggi pada kolom X (max) = 10\nLalu untuk menentukan nilai X yang telah dinormalisasi maka dengan menghitung setiap baris data yang dimasukkan kedalam rumus Min-Max Scaling seperti berikut:\n\n\n\n\nX\nX`\n\n\n\n\n2\n(2 - 2) / ( 10 - 2)\n\n\n4\n(4 - 2) / ( 10 - 2)\n\n\n3\n(3 - 2) / ( 10 - 2)\n\n\n10\n(10 - 2) / ( 10 - 2)\n\n\n\n\nSehingga nilai X’ hasil normalisasi dapat diketahui seperti berikut :\n\n\n\n\nX\nX`\n\n\n\n\n2\n0\n\n\n4\n0.25\n\n\n3\n0.125\n\n\n10\n1\n\n\n\n\nimport pickle\nfrom sklearn.preprocessing import MinMaxScaler\n\n# menentukan lokasi file pickle akan disimpan\npath = 'minmax_scaler_ckd.pkl'\n\n# membuat dan melatih objek MinMaxScaler\nminmaxscaler = MinMaxScaler()\nminmaxscaler.fit(fitur_train)\n\n# menyimpan model ke dalam file pickle\nwith open(path, 'wb') as file:\n    pickle.dump(minmaxscaler, file)\n\n# memanggil kembali model normalisasi minmaxscaler dari file pickle\nwith open(path, 'rb') as file:\n    minmaxscaler = pickle.load(file)\n\n# menerapkan normalisasi zscore pada data training\nminmax_training = minmaxscaler.transform(fitur_train)\n\n# menerapkan normalisasi zscore pada data testing\nminmax_testing = minmaxscaler.transform(fitur_test)"
  },
  {
    "objectID": "Chronic_Kidney_Disease.html#modeling",
    "href": "Chronic_Kidney_Disease.html#modeling",
    "title": "1  ——————————– TUGAS PROYEK SAINS DATA ——————————-",
    "section": "1.4 4. MODELING",
    "text": "1.4 4. MODELING\n\nSetelah dilakukan skenario perulangan untuk menghasilkan model terbaik, dapat dikeathui bahwasannya model klasifikasi yang terbaik untuk data anggur merah ini adalah dengan menggunakan : - Metode Random Forest - Metode normalisasi nya adalah Zscore Scaler - Banyak Fitur yang digunakan dalam data sebanyak 19 fitur - Parameter dalam metode yang digunakan, sebagai berikut:\n\n\njumlah estimator : 50, 100, 200\nmaksimal kedalaman : None, 10, 20, 30\nminimal pembagian sampel : 2, 5, 10\nminimal sampel daun : 1, 2, 4\n\n\n\n1.4.1 RANDOM FOREST\n\nRandom Forest adalah algoritma pembelajaran terawasi yang digunakan untuk tugas klasifikasi dan regresi dalam machine learning. Ini merupakan bagian dari keluarga algoritma yang dikenal sebagai ensemble learning, yang menggabungkan hasil beberapa model untuk meningkatkan kinerja dan ketepatan prediksi.\nKonsep inti dari Random Forest adalah membuat sejumlah besar pohon keputusan saat melakukan prediksi. Setiap pohon keputusan dibuat berdasarkan sampel acak dari data pelatihan dan fitur yang dipilih secara acak. Proses ini mengurangi risiko overfitting (memfitting data pelatihan secara berlebihan) yang sering terjadi pada pohon keputusan tunggal.\nSelama proses pelatihan, setiap pohon keputusan dalam hutan acak memilih subset data yang diambil secara acak dan subset fitur untuk membuat keputusan. Ketika melakukan prediksi, setiap pohon memberikan hasilnya, dan hasil akhir dari Random Forest diperoleh dengan mengambil mayoritas suara dari semua pohon keputusan (untuk klasifikasi) atau rerata hasil (untuk regresi).\nKelebihan dari Random Forest termasuk kemampuannya dalam menangani data yang besar dengan fitur yang banyak, serta kemampuan untuk mengatasi overfitting. Namun, seperti halnya dengan banyak algoritma machine learning, pengaturan parameter yang tidak tepat atau kekurangan pemrosesan data yang tepat dapat mempengaruhi kinerja Random Forest.\nRandom Forest terdiri dari beberapa pohon keputusan yang dibuat secara acak. Untuk setiap pohon keputusan:\n\nSampling Data: Lakukan bootstrap sampling pada dataset (ambil sampel acak dengan penggantian).\nBootstrap Sampling: Proses pengambilan sampel acak dengan penggantian dari dataset yang sama ukuran dengan dataset asli.\nPemilihan Jumlah Pohon (n_estimators): Tentukan jumlah pohon keputusan yang akan dibuat dalam Random Forest.\nPemilihan Fitur: Ambil subset acak dari fitur-fitur yang tersedia untuk membangun pohon.\nPembentukan Pohon: Gunakan algoritma pembentukan pohon (seperti CART atau ID3) untuk membagi data berdasarkan aturan yang paling informatif.\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import accuracy_score\nimport pickle\n# Definisi parameter grid untuk Random Forest\nparam_grid = {\n    'n_estimators': [50, 100, 200],  # Jumlah pohon dalam ensemble\n    'max_depth': [None, 10, 20, 30],  # Kedalaman maksimum pohon\n    'min_samples_split': [2, 5, 10],  # Jumlah minimum sampel yang diperlukan untuk membagi simpul\n    'min_samples_leaf': [1, 2, 4],  # Jumlah minimum sampel di ujung daun\n}\n\n# Inisialisasi model Random Forest\nrf_classifier = RandomForestClassifier()\n\n# Grid Search dengan model Random Forest dan parameter grid\ngrid_search = GridSearchCV(estimator=rf_classifier, param_grid=param_grid, cv=5, scoring='accuracy')\ngrid_search.fit(zscore_training, target_train)\n\n# Cetak parameter terbaik\nprint(\"Best Parameters:\", grid_search.best_params_)\n\nbest_n_estimators = grid_search.best_params_['n_estimators']\nbest_max_depth = grid_search.best_params_['max_depth']\nbest_min_samples_split = grid_search.best_params_['min_samples_split']\nbest_min_samples_leaf = grid_search.best_params_['min_samples_leaf']\n\n\n\nBest Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n\n\n\n# Inisialisasi model Random Forest dengan parameter terbaik\nbest_rf_model = RandomForestClassifier(\n    n_estimators=best_n_estimators,\n    max_depth=best_max_depth,\n    min_samples_split=best_min_samples_split,\n    min_samples_leaf=best_min_samples_leaf\n)\n\n# Melatih model terbaik pada data training\nbest_rf_model.fit(zscore_training, target_train)\n\n# Melakukan prediksi dan mengukur akurasi pada data testing\ny_pred = best_rf_model.predict(zscore_testing)\nbest_accuracy = accuracy_score(target_test, y_pred)\n\nprint(\"Best Accuracy:\", best_accuracy)\n\n# Simpan model Random Forest terbaik dan informasi terkait dalam file pickle\n# best_model_info = {\n#     'best_rf_model': best_rf_model\n# }\n\nfrom joblib import dump, load\n\n# ...\n\n# menyimpan model dengan joblib\n# dump(best_model_info, 'best_rf_model_zscore_ckd.joblib')\n\nwith open('best_rf_model_zscore_ckd.pkl', 'wb') as model_file:\n    pickle.dump(best_rf_model, model_file)\n\nBest Accuracy: 1.0"
  },
  {
    "objectID": "Chronic_Kidney_Disease.html#evaluasi-model",
    "href": "Chronic_Kidney_Disease.html#evaluasi-model",
    "title": "1  ——————————– TUGAS PROYEK SAINS DATA ——————————-",
    "section": "1.5 EVALUASI MODEL",
    "text": "1.5 EVALUASI MODEL\n\nPada tahap ini model terbaik yang diperoleh pada tahap modeling dilakukan validasi dengan menampilkan nilai confusion matrix nya atau laporan klasifikasinya dengan menggunakan grafik ROC-AUC\n\n1.5.1 CONFUSION MATRIX\n\nConfusion matrix adalah sebuah tabel yang digunakan dalam evaluasi kinerja model klasifikasi untuk memahami performa model dalam memprediksi kelas-kelas target. Matrix ini memiliki empat sel yang mewakili:\n\nTrue Positive (TP): Prediksi yang benar ketika kelas sebenarnya adalah positif.\nTrue Negative (TN): Prediksi yang benar ketika kelas sebenarnya adalah negatif.\nFalse Positive (FP): Prediksi yang salah ketika model memprediksi positif tetapi kelas sebenarnya negatif (juga dikenal sebagai Type I error).\nFalse Negative (FN): Prediksi yang salah ketika model memprediksi negatif tetapi kelas sebenarnya positif (juga dikenal sebagai Type II error).\n\nBentuk dari tabel Confusion Matrix\n\n\n\n\nPredicted Negative\nPredicted Positive\n\n\n\n\nActual Negative\nTrue Negative (TN)\nFalse Positive (FP)\n\n\nActual Positive\nFalse Negative (FN)\nTrue Positive (TP)\n\n\n\nDari Confusion Matriks, kta dapat menghitung metrik evaluasi seperti akurasi, presisi, recall, F1-score, dan lainnya yang membantu dalam mengevaluasi performa model klasifikasi.\nMetrik Evaluasi\nMetrik evaluasi adalah ukuran atau parameter yang digunakan untuk mengevaluasi kinerja suatu model atau sistem dalam melakukan tugas tertentu, seperti klasifikasi, regresi, atau tugas lainnya dalam bidang machine learning dan statistika. Metrik-metrik ini membantu dalam memahami seberapa baik atau buruk model tersebut dalam melakukan prediksi atau tugas yang ditetapkan.\nBeberapa metrik evaluasi umum dalam machine learning termasuk: &gt; - Akurasi (Accuracy): Seberapa sering model memberikan prediksi yang benar secara keseluruhan. Rumus Akurasi : \\[ Accuracy = \\frac{TN + TP}{TN + FP + FN + TP} \\] &gt; - Presisi (Precision): Proporsi dari prediksi positif yang benar dibandingkan dengan semua prediksi positif yang dibuat oleh model Rumus Precision : \\[ Precision = \\frac{TP}{TP + FP} \\] &gt; - Recall (Sensitivity atau True Positive Rate): Proporsi dari kelas positif yang diprediksi dengan benar oleh model. Rumus Recall : \\[ Recall = \\frac{TP}{TP + FN} \\] &gt; - F1-Score: Nilai rata-rata harmonik antara presisi dan recall. Berguna ketika perlu menyeimbangkan antara presisi dan recall. Rumus F1-Score : \\[ F1-Score = 2 x \\frac {Presisi x Recall}{Presisi x Recall} \\] &gt; - Specificity (Specificity atau True Negative Rate): Proporsi dari kelas negatif yang diprediksi dengan benar oleh model. Rumus Specificity : \\[ Specificity = \\frac{TN}{TN + FP} \\]\n\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score,roc_curve\n\n# Evaluasi model dengan data uji Zscore\nprint(\"\\nEVALUASI MODEL DENGAN DATA UJI ZSCORE\")\nprint(\"Confusion Matrix Zscore:\")\nconf_matrix = confusion_matrix(target_test, y_pred)\nprint(conf_matrix)\n\n# Mendapatkan nilai TP, TN, FP, FN dari confusion matrix\nTN = conf_matrix[0, 0]\nFP = conf_matrix[0, 1]\nFN = conf_matrix[1, 0]\nTP = conf_matrix[1, 1]\n\nprint(\"\\nTrue Positive (TP):\", TP)\nprint(\"True Negative (TN):\", TN)\nprint(\"False Positive (FP):\", FP)\nprint(\"False Negative (FN):\", FN)\n\nprint(\"\\nClassification Report Zscore:\")\nprint(classification_report(target_test, y_pred))\nprint(\"ROC-AUC Score Zscore:\", roc_auc_score(target_test, y_pred))\n\n\nEVALUASI MODEL DENGAN DATA UJI ZSCORE\nConfusion Matrix Zscore:\n[[27  0]\n [ 0 50]]\n\nTrue Positive (TP): 50\nTrue Negative (TN): 27\nFalse Positive (FP): 0\nFalse Negative (FN): 0\n\nClassification Report Zscore:\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        27\n           1       1.00      1.00      1.00        50\n\n    accuracy                           1.00        77\n   macro avg       1.00      1.00      1.00        77\nweighted avg       1.00      1.00      1.00        77\n\nROC-AUC Score Zscore: 1.0\n\n\n\n\n1.5.2 GRAFIK ROC-AUC\n\nMetrik evaluasi ROC (Receiver Operating Characteristic) dan AUC (Area Under the ROC Curve) adalah alat evaluasi yang digunakan untuk mengukur kinerja model klasifikasi, terutama ketika model harus mengklasifikasikan antara dua kelas.\nReceiver Operating Characteristic (ROC) Curve\nROC Curve adalah adalah kurva grafik yang menampilkan kinerja model klasifikasi pada berbagai tingkat cutoff (threshold) untuk membedakan antara kelas positif dan negatif. Didalam ROC kurva dapat diketahui sensitivity (True Positive Rate) dan False Positive Rate (1-Specificity), untuk menunjukkan seberapa baik model klasifikasi sehingga dapat membedakan antara kelas positif dan negatif.\nArea Under the ROC Curve (AUC-ROC):\nAUC-ROC adalah ukuran dari luas area di bawah kurva ROC.\n\nInterpretasi : Nilai AUC berkisar antara 0 hingga 1. Semakin dekat nilainya ke 1, semakin baik model dalam membedakan antara kelas positif dan negatif. Jika nilainya 0.5, itu menunjukkan klasifikasi acak.\n\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_auc_score,roc_curve\nimport matplotlib.pyplot as plt\n\n# Normalisasi Z-score pada data uji\nscaler = StandardScaler()\ny_pred_zscore = scaler.fit_transform(y_pred.reshape(-1, 1))  # Reshape agar sesuai dengan format yang diharapkan oleh fit_transform\n\n# Kurva ROC-AUC untuk model dengan data uji Z-score\nfpr_zscore, tpr_zscore, thresholds_zscore = roc_curve(target_test, y_pred_zscore)\nroc_auc_zscore = roc_auc_score(fpr_zscore, tpr_zscore)\n\nplt.figure(figsize=(8, 6))\nplt.plot(fpr_zscore, tpr_zscore, label='ROC Curve Z-score (area = %0.2f)' % roc_auc_zscore)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver Operating Characteristic (ROC) Curve Z-score')\nplt.legend(loc='lower right')\nplt.show()"
  },
  {
    "objectID": "Chronic_Kidney_Disease.html#deployment",
    "href": "Chronic_Kidney_Disease.html#deployment",
    "title": "1  ——————————– TUGAS PROYEK SAINS DATA ——————————-",
    "section": "1.6 5. Deployment",
    "text": "1.6 5. Deployment\nPada tahap deployment, menggunakan streamlit dengan file yang berekstensi .py . File yang dilakukan pengolahan yaitu sebagai berikut : - model normalisasi ZsCore yang disimpan dalam file pickle - model dengan algoritma terbaik pada pengolahan data ini yaitu Random Forest"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  }
]